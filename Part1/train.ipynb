{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from retinanet import model, csv_eval\n",
    "from retinanet.dataloader import CSVDataset, collater, Resizer, AspectRatioBasedSampler, Augmenter, Normalizer\n",
    "\n",
    "assert torch.__version__.split('.')[0] == '1'\n",
    "\n",
    "print('CUDA available: {}'.format(torch.cuda.is_available()))\n",
    "\n",
    "\n",
    "dataset_name = 'csv_test'\n",
    "csv_train = 'visDrone_train.csv'\n",
    "csv_classes = 'classes.csv'\n",
    "csv_val = 'visDrone_valid.csv'\n",
    "epochs = 20 #100\n",
    "\n",
    "\n",
    "# Create the data loader\n",
    "dataset_train = CSVDataset(train_file=csv_train, class_list=csv_classes,\n",
    "                               transform=transforms.Compose([Normalizer(), Augmenter(), Resizer()]))\n",
    "\n",
    "if csv_val is None:\n",
    "    dataset_val = None\n",
    "    print('No validation annotations provided.')\n",
    "else:\n",
    "    dataset_val = CSVDataset(train_file=csv_val, class_list=csv_classes,\n",
    "                                transform=transforms.Compose([Normalizer(), Resizer()]))\n",
    "\n",
    "sampler = AspectRatioBasedSampler(dataset_train, batch_size=2, drop_last=False)\n",
    "dataloader_train = DataLoader(dataset_train, num_workers=3, collate_fn=collater, batch_sampler=sampler)\n",
    "\n",
    "if dataset_val is not None:\n",
    "    sampler_val = AspectRatioBasedSampler(dataset_val, batch_size=1, drop_last=False)\n",
    "    dataloader_val = DataLoader(dataset_val, num_workers=3, collate_fn=collater, batch_sampler=sampler_val)\n",
    "\n",
    "# Create the model\n",
    "# resnet sizes 18, 34, 50, 101, and 152\n",
    "retinanet = model.resnet50(num_classes=dataset_train.num_classes(), pretrained=True)\n",
    "\n",
    "use_gpu = True\n",
    "\n",
    "if use_gpu:\n",
    "    if torch.cuda.is_available():\n",
    "        retinanet = retinanet.cuda()\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    retinanet = torch.nn.DataParallel(retinanet).cuda()\n",
    "else:\n",
    "    retinanet = torch.nn.DataParallel(retinanet)\n",
    "\n",
    "retinanet.training = True\n",
    "\n",
    "optimizer = optim.Adam(retinanet.parameters(), lr=1e-5)\n",
    "\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=3, verbose=True)\n",
    "\n",
    "loss_hist = collections.deque(maxlen=500)\n",
    "\n",
    "retinanet.train()\n",
    "retinanet.module.freeze_bn()\n",
    "\n",
    "print('Num training images: {}'.format(len(dataset_train)))\n",
    "\n",
    "for epoch_num in range(epochs):\n",
    "\n",
    "    retinanet.train()\n",
    "    retinanet.module.freeze_bn()\n",
    "\n",
    "    epoch_loss = []\n",
    "\n",
    "    for iter_num, data in enumerate(dataloader_train):\n",
    "        try:\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            if torch.cuda.is_available():\n",
    "                classification_loss, regression_loss = retinanet([data['img'].cuda().float(), data['annot']])\n",
    "            else:\n",
    "                classification_loss, regression_loss = retinanet([data['img'].float(), data['annot']])\n",
    "\n",
    "            classification_loss = classification_loss.mean()\n",
    "            regression_loss = regression_loss.mean()\n",
    "\n",
    "            loss = classification_loss + regression_loss\n",
    "\n",
    "            if bool(loss == 0):\n",
    "                continue\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            torch.nn.utils.clip_grad_norm_(retinanet.parameters(), 0.1)\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            loss_hist.append(float(loss))\n",
    "\n",
    "            epoch_loss.append(float(loss))\n",
    "\n",
    "            print(\n",
    "                'Epoch: {} | Iteration: {} | Classification loss: {:1.5f} | Regression loss: {:1.5f} | Running loss: {:1.5f}'.format(\n",
    "                    epoch_num, iter_num, float(classification_loss), float(regression_loss), np.mean(loss_hist)))\n",
    "\n",
    "            del classification_loss\n",
    "            del regression_loss\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            continue\n",
    "\n",
    "\n",
    "    if csv_val is not None:\n",
    "\n",
    "        print('Evaluating dataset')\n",
    "\n",
    "        mAP = csv_eval.evaluate(dataset_val, retinanet)\n",
    "\n",
    "    scheduler.step(np.mean(epoch_loss))\n",
    "\n",
    "    torch.save(retinanet.module, '{}_retinanet_{}.pt'.format(dataset_name, epoch_num))\n",
    "\n",
    "retinanet.eval()\n",
    "\n",
    "torch.save(retinanet, 'trained_model/model_final.pt')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}